## ðŸ”· **Hadoop kya hai?**

Hadoop ek **open-source framework** hai jo **large data** ko process karne ke liye use hota hai. Ye **data ko store** bhi karta hai aur **analyze** bhi.

### ðŸ”¹ History of Hadoop:

* Iska idea **Google ke paper "MapReduce"** se aaya.
* **Doug Cutting** ne isko banaya, aur isne apne bete ke toy elephant ka naam "Hadoop" isko diya.
* Pehle **Yahoo** ne isko adopt kiya, phir **Apache Software Foundation** ke under isko launch kiya gaya.

---

## ðŸ”· **Apache Hadoop:**

Apache Hadoop ek **platform** hai jisme kai components milke kaam karte hain:

1. **HDFS (Hadoop Distributed File System)** â€“ Data store karta hai.
2. **MapReduce** â€“ Data process karta hai.
3. **YARN (Yet Another Resource Negotiator)** â€“ Resource manage karta hai.
4. **Common Utilities** â€“ Baki tools ke liye support provide karta hai.

---

## ðŸ”· **HDFS (Hadoop Distributed File System):**

Samjho tumhare paas 1 TB ka file hai. Isse ek normal system me rakhna mushkil hai.

### Example:

Agar tumhare paas 10 computers ka cluster hai, toh HDFS is 1 TB file ko **blocks** me todta hai (jaise 128 MB ke parts) aur sabhi computers pe **distributed** way me save kar deta hai.

* Har block ka **replica (copy)** 3 jagah rakha jaata hai for safety.
* Agar ek system fail ho jaaye, toh data lost nahi hota.

---

## ðŸ”· **Components of Hadoop:**

1. **HDFS** â€“ Storage ke liye
2. **MapReduce** â€“ Processing ke liye
3. **YARN** â€“ Job scheduling aur resource allocation
4. **Hadoop Common** â€“ Jaruri libraries aur files

---

## ðŸ”· **Data Format in Hadoop:**

Hadoop mostly use karta hai:

* **Text files**
* **Sequence files**
* **Avro, Parquet** (for structured data)
* Binary formats (efficient data processing ke liye)

---

## ðŸ”· **Analyzing Data with Hadoop:**

Tum petabytes (1 PB = 1000 TB) ka data analyze kar sakte ho MapReduce jobs ke through.

### Example:

Tumhare paas Flipkart ka data hai â€” kaunse product sabse zyada bik rahe hain? Kis time pe sale zyada hoti hai? MapReduce se ye sab analyze kiya ja sakta hai.

---

## ðŸ”· **Scaling Out (Horizontal Scaling):**

Jab data badh jaaye, toh tumhe naye computers (nodes) add karne padte hain cluster me. Isse **horizontal scaling** kehte hain.

* Hadoop easily scale ho jaata hai by adding new machines.

---

## ðŸ”· **Hadoop Streaming:**

Yeh allow karta hai tumhe **Python, Perl, Bash scripts** se MapReduce likhne ki ability, bina Java ke.

---

## ðŸ”· **Hadoop Pipes:**

Agar tum C++ me programming karna chahte ho Hadoop ke saath, toh **Pipes** use karte ho.

---

## ðŸ”· **Hadoop Ecosystem:**

Ye tools Hadoop ke aas-paas kaam karte hain:

| Tool      | Kaam                          |
| --------- | ----------------------------- |
| Hive      | SQL-like queries for big data |
| Pig       | Data flow language            |
| HBase     | NoSQL database                |
| Sqoop     | RDBMS â†” Hadoop                |
| Flume     | Streaming data ingestion      |
| Oozie     | Job scheduling                |
| Zookeeper | Coordination service          |
| Mahout    | Machine Learning              |
| Spark     | Fast in-memory processing     |

---

## ðŸ”· **MapReduce:**

MapReduce ek **programming model** hai jo data ko **map** karta hai (sort & filter) aur phir **reduce** karta hai (aggregate or summarize).

---

### ðŸ”¹ How MapReduce Works (Simple Example):

**Problem:** Tumhare paas 1 lakh logon ke shopping invoices hain. Tumhe dekhna hai ki **kis product ka kitna sale hua**.

#### Step 1: Map

Har invoice ka ek item lo aur uska count 1 karo.

```text
Map Output:
Shoes â†’ 1
Shirt â†’ 1
Shoes â†’ 1
Shoes â†’ 1
Shirt â†’ 1
```

#### Step 2: Shuffle and Sort

Same keys (products) ek jagah group ho jaate hain.

```text
Grouped:
Shoes â†’ [1, 1, 1]
Shirt â†’ [1, 1]
```

#### Step 3: Reduce

Group ki values ko add karo.

```text
Reduce Output:
Shoes â†’ 3
Shirt â†’ 2
```

---

## ðŸ”· **MapReduce Job Run (Anatomy):**

1. **Client** job submit karta hai.
2. **YARN** job ko allocate karta hai.
3. **Map tasks** start hote hain â†’ intermediate data banta hai.
4. **Reduce tasks** run hote hain â†’ final result aata hai.

---

## ðŸ”· **Failures in MapReduce:**

* Agar koi task fail ho jaata hai, toh Hadoop us task ko **automatically retry** karta hai kisi aur node pe.

---

## ðŸ”· **Job Scheduling:**

YARN decide karta hai kis node pe kaun sa task chalega based on availability.

---

## ðŸ”· **Shuffle and Sort:**

Map ke baad jo output aata hai, usko **sort** aur **group** karke reducers tak bhejna â€” is process ko shuffle & sort kehte hain.

---

## ðŸ”· **MapReduce Types:**

1. **Mapper only**
2. **Reducer only**
3. **Mapper + Reducer**
4. **Combiner** (Mini reducer jo mapper ke baad run karta hai)

---

## ðŸ”· **Input/Output Formats:**

* **Input:** TextInputFormat, KeyValueTextInputFormat
* **Output:** TextOutputFormat, SequenceOutputFormat

---

## ðŸ”· **Real-world Use Cases of MapReduce:**

1. **Web indexing** â€“ Google style
2. **Log analysis** â€“ Server logs
3. **Retail analytics** â€“ Top selling items
4. **Social media trends** â€“ Hashtag analysis

---

